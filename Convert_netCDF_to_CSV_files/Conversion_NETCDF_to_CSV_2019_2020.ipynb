{"cells":[{"cell_type":"markdown","id":"c541a020","metadata":{"id":"c541a020"},"source":["# Converting netCDF to CSV format\n","### Objective:\n","- netCDF files are large size and can take much more resource to compute for data analysis\n","- Converting to csv format uses less resource\n","\n","### STEPS: \n","* EXPLORE the Files from all directories and CONCATENATE as a single path\n","* Collect the files paths from different directories\n","* final output: csv files format"]},{"cell_type":"code","execution_count":1,"id":"9a680156","metadata":{"id":"9a680156","executionInfo":{"status":"ok","timestamp":1652679167658,"user_tz":420,"elapsed":4,"user":{"displayName":"Kikipessa Doll","userId":"16203075636725704864"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import matplotlib\n","import os\n","import netCDF4 as nc\n","\n","# converting the datetime format\n","from datetime import datetime"]},{"cell_type":"markdown","id":"ab238c96","metadata":{"id":"ab238c96"},"source":["# Path to NETCDF files\n","- Locate the downloaded netcdf files directory"]},{"cell_type":"code","execution_count":4,"id":"1fa1e6c8","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":236},"id":"1fa1e6c8","executionInfo":{"status":"error","timestamp":1652679503238,"user_tz":420,"elapsed":214,"user":{"displayName":"Kikipessa Doll","userId":"16203075636725704864"}},"outputId":"7e95debd-55c7-47b2-e114-2120a08c6304"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-9de3526be9aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Collect the paths of each individual files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfile_names\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmultiple_netcdf_files\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'multiple_netcdf_files' is not defined"]}],"source":["path_a= ('multiple_netcdf_files/')\n","\n","# Collect the paths of each individual files\n","file_names= [multiple_netcdf_files]\n","\n","for file in os.listdir(path_a):\n","    # Check whether file is in text format or not\n","    if file.endswith(\".nc4\"):\n","        file_path = f\"{path_a}\\{file}\"\n","      \n","        # Store the path location of each individual files\n","        file_names.append(file_path)\n","        \n","        \n","# check first 10 files path\n","file_names[:10]"]},{"cell_type":"markdown","id":"004626ef","metadata":{"id":"004626ef"},"source":["# NOTE: Select the Root PATH for files on different folders\n","- Run this script below if the individual files are located in seperate folders\n","- How it works: \n","    - 1. Provide the root direcoty\n","    - 2. Loop searches individual files at end paths of each directories\n","    - 3. Concatenates the path from ROOT dir. to individual file path from each dir."]},{"cell_type":"code","execution_count":null,"id":"5ced6be4","metadata":{"id":"5ced6be4"},"outputs":[],"source":["# # list fo FILES 2021\n","# file_path_2021= []\n","\n","# for root, dirs, files in os.walk('../../../Clusters_DATA_oil/OCO-2/2018/'):\n","#     for filename in files:\n","#         print(os.path.join(root, filename))\n","        \n","#         # Append the files into list\n","#         file_path_2021.append(os.path.join(root, filename))"]},{"cell_type":"code","execution_count":null,"id":"d457322a","metadata":{"id":"d457322a"},"outputs":[],"source":["#files= os.listdir('../ENTIRE_datasets/OCO-2_datasets/2019_2020/')\n","\n","# files= os.listdir('')\n","# # LISTING the path of FILES\n","# files"]},{"cell_type":"markdown","id":"e4a27bf7","metadata":{"id":"e4a27bf7"},"source":["# Example: \n","### Opening a single file in netCDF format"]},{"cell_type":"code","execution_count":null,"id":"71c5c0f8","metadata":{"id":"71c5c0f8"},"outputs":[],"source":["df_xco2= nc.Dataset('multiple_netcdf_files/oco2_LtCO2_190101_B10206Ar_200729172616s.nc4')"]},{"cell_type":"code","execution_count":null,"id":"cf971e06","metadata":{"id":"cf971e06","outputId":"10af2033-b003-4841-d57c-cc5db550fcb7"},"outputs":[{"data":{"text/plain":["['sounding_id',\n"," 'levels',\n"," 'bands',\n"," 'vertices',\n"," 'footprints',\n"," 'date',\n"," 'latitude',\n"," 'longitude',\n"," 'time',\n"," 'solar_zenith_angle',\n"," 'sensor_zenith_angle',\n"," 'xco2_quality_flag',\n"," 'xco2_qf_bitflag',\n"," 'xco2_qf_simple_bitflag',\n"," 'source_files',\n"," 'file_index',\n"," 'vertex_latitude',\n"," 'vertex_longitude',\n"," 'xco2',\n"," 'xco2_uncertainty',\n"," 'xco2_apriori',\n"," 'pressure_levels',\n"," 'co2_profile_apriori',\n"," 'xco2_averaging_kernel',\n"," 'pressure_weight']"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["list(df_xco2.variables.keys())"]},{"cell_type":"markdown","id":"5539e984","metadata":{"id":"5539e984"},"source":["### Filtering specific attributes from the netCDF files\n","- xco2\n","- xco2_quality_flag\n","- latitude\n","- longitude\n","- sounding_id (DateTime)"]},{"cell_type":"markdown","id":"4a107b29","metadata":{"id":"4a107b29"},"source":["***********************************************************************************************\n","***********************************************************************************************\n","***********************************************************************************************"]},{"cell_type":"markdown","id":"8f1aa9ba","metadata":{"id":"8f1aa9ba"},"source":["# DateTime format Change"]},{"cell_type":"code","execution_count":null,"id":"4133c955","metadata":{"id":"4133c955"},"outputs":[],"source":["# DATE time function\n","def conv_date(d):\n","    return datetime.strptime(str(d), '%Y%m%d%H%M%S%f')"]},{"cell_type":"markdown","id":"cd2ad694","metadata":{"id":"cd2ad694"},"source":["# Check the total files in the DIRECTORY"]},{"cell_type":"code","execution_count":null,"id":"de96547b","metadata":{"id":"de96547b","outputId":"2c929c0a-183e-447c-d3cb-2bdb0dba76ba"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","TotalFiles:  9\n"]}],"source":["countFiles=0\n","\n","for j in file_names:\n","    if j.endswith(\".nc4\"):\n","        countFiles+=1\n","        #print(j)\n","        \n","print('\\nTotalFiles: ', countFiles)"]},{"cell_type":"markdown","id":"a9b752b4","metadata":{"id":"a9b752b4"},"source":["### Function:\n","* Function below takes individual path of files and converts to CSV/TXT format\n","* Converted files are created on the same dir. of the code"]},{"cell_type":"markdown","id":"efa6486c","metadata":{"id":"efa6486c"},"source":["# Storing the files on specified directory: csv_files folder"]},{"cell_type":"code","execution_count":null,"id":"5dbdf3b9","metadata":{"id":"5dbdf3b9"},"outputs":[],"source":["#creatin g a FOLDER\n","current_directory= os.getcwd()\n","frames_folder= os.path.join(current_directory, r'csv_files')\n","\n","if not os.path.exists(frames_folder):\n","    os.makedirs(frames_folder)"]},{"cell_type":"markdown","id":"d7d135ca","metadata":{"id":"d7d135ca"},"source":["### NOTE:\n","- Refine the ENTIRE dataframe by GOOD quality_flag->0\n","- NOTE: REDUCES the size of the file"]},{"cell_type":"code","execution_count":null,"id":"5bfa8617","metadata":{"id":"5bfa8617"},"outputs":[],"source":["# FUNCTION to convert data\n","\n","def convHdf(path_file, n=0):\n","\n","    data= nc.Dataset(path_file)\n","\n","    # get the HDF data and convert to CSV\n","    df_xco2= pd.DataFrame()\n","\n","    df_xco2['Xco2']= data.variables['xco2'][:]\n","    df_xco2['Latitude']= data.variables['latitude'][:]\n","    df_xco2['Longitude']= data.variables['longitude'][:] \n","    df_xco2['quality_flag']= data.variables['xco2_quality_flag'][:] \n","    \n","    # Date\n","    df_xco2['DateTime']= data.variables['sounding_id'][:]\n","    \n","    #Convert soundingID to datetime format\n","    df_xco2['DateTime']= df_xco2['DateTime'].apply(conv_date)\n","    df_xco2['DateTime']= pd.to_datetime(df_xco2['DateTime'])\n","    \n","    # YEAR and month column\n","    df_xco2['Year']= df_xco2['DateTime'].dt.year\n","    df_xco2['Month']= df_xco2['DateTime'].dt.month\n","    df_xco2['Day']= df_xco2['DateTime'].dt.day\n","    \n","    # Refine the ENTIRE dataframe by GOOD quality_flag->0\n","    # NOTE: REDUCES the size of the file\n","    df_xco2= df_xco2[df_xco2['quality_flag'] == 0]   \n","    \n","   \n","    date= str(data.variables['sounding_id'][0])      \n","    \n","    # create a CSV and store on new folder: csv_files\n","    df_xco2.to_csv('csv_files'+'/'+ data.Sensor+'_xco2_'+ date+'_.txt', index= False)"]},{"cell_type":"markdown","id":"7140ef72","metadata":{"id":"7140ef72"},"source":["# OCO3 for SIF conversion"]},{"cell_type":"code","execution_count":null,"id":"fbbfabb7","metadata":{"id":"fbbfabb7"},"outputs":[],"source":["# # FUNCTION to convert data\n","# def convOCO3(path_file, n=0):\n","\n","#     #path= '../hdf_format/Los_angeles_GROUPED/'\n","#     data= nc.Dataset(path_file)\n","\n","#     # get the HDF data and convert to CSV\n","#     df_sif= pd.DataFrame()\n","\n","#     df_sif['sif_757nm']= data.variables['Daily_SIF_757nm'][:]\n","#     df_sif['Latitude']= data.variables['Latitude'][:]\n","#     df_sif['Longitude']= data.variables['Longitude'][:] \n","#     df_sif['quality_flag']= data.variables['Quality_Flag'][:] \n","    \n","#     # Date\n","#     # Date time not found \n","# #     df_xco2['DateTime']= data.variables['sounding_id'][:]\n","    \n","# #     #Convert soundingID to datetime format\n","# #     df_xco2['DateTime']= df_xco2['DateTime'].apply(conv_date)\n","# #     df_xco2['DateTime']= pd.to_datetime(df_xco2['DateTime'])\n","    \n","# #     # YEAR and month column\n","# #     df_xco2['Year']= df_xco2['DateTime'].dt.year\n","# #     df_xco2['Month']= df_xco2['DateTime'].dt.month\n","# #     df_xco2['Day']= df_xco2['DateTime'].dt.day\n","    \n","    \n","#     # xco2 quality flag -> 0\n","#  #   df_sif= df_sif[df_sif['quality_flag'] == 0]\n","    \n","# #    date= str(data.variables['sounding_id'][0])                                   \n","#     # create a CSV\n","#     # OCO3 sensor\n","#     df_sif.to_csv(data.sensor[:5]+'_sif_'+str(n)+ '_.txt', index= False)\n","# #     df_xco2.to_feather(data.Sensor+'_xco2_'+ date+'_.txt')"]},{"cell_type":"markdown","id":"1506ef2f","metadata":{"id":"1506ef2f"},"source":["# Testing: Single files transformation"]},{"cell_type":"code","execution_count":null,"id":"6be0ec39","metadata":{"id":"6be0ec39"},"outputs":[],"source":["convHdf(file_names[0])"]},{"cell_type":"markdown","id":"4c367997","metadata":{"id":"4c367997"},"source":["## NOTE: Filtering XCO2 quality flag(0) to reduce the total size of file"]},{"cell_type":"code","execution_count":null,"id":"221c73b6","metadata":{"id":"221c73b6"},"outputs":[],"source":["# using Function to READ FILES from the direcotry and convert all netCDF files to csv/txt    \n","\n","for j in range(0, len(file_names)):\n","  \n","       # EG to read FIRST dataset from THE DIRECTORY       \n","        convHdf(file_names[j], j)"]},{"cell_type":"code","execution_count":null,"id":"8d89d124","metadata":{"id":"8d89d124"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"id":"194416c5","metadata":{"id":"194416c5"},"outputs":[],"source":[""]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"colab":{"name":"Conversion_NETCDF_to_CSV_2019_2020.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":5}