{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c541a020",
   "metadata": {
    "id": "c541a020"
   },
   "source": [
    "## Objective: Converting netCDF to CSV format\n",
    "\n",
    "- `netCDF` files often possess substantial sizes, which can necessitate significant computational resources for efficient data analysis. This is because larger files typically require more memory and processing power to manipulate and extract valuable information.\n",
    "- Streamlining the netCDF file by applying filtering techniques is a crucial step in extracting only the essential attributes and features needed for analysis. Filtering or subsetting netCDF files involves selecting specific variables, time periods, or spatial regions from the original file. This selective approach helps analysts focus on the relevant data, reducing the amount of information that needs to be processed.\n",
    "- The following variables are extracted from the netCDF files:\n",
    "    * sounding_id => DateTime\n",
    "    * Xco2 => XCO2 ppm\n",
    "    * Latitude, Longitude => Latitude, Longitude\n",
    "    * xco2_quality_flag => xco2_quality_flag ( 0 =>good quality, 1 => bad quality)\n",
    "\n",
    "### Steps and Pre-requisites:\n",
    "- this is a begineer level tutorial, if you have already pre-processed and prepared data-ready for visualization you can skip this part\n",
    "- You can obtain files by downloading them from publicly accessible web servers like **EarthData, OpenDAP** and specifying the destination directory. For more information, check the main homepage of the current git repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a680156",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1652679167658,
     "user": {
      "displayName": "Kikipessa Doll",
      "userId": "16203075636725704864"
     },
     "user_tz": 420
    },
    "id": "9a680156"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import os\n",
    "import netCDF4 as nc\n",
    "\n",
    "# converting the datetime format\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab238c96",
   "metadata": {
    "id": "ab238c96"
   },
   "source": [
    "## File location:\n",
    "To effectively manage your downloaded files, it's crucial to ascertain their storage arrangement. This code documentation provides guidance on distinguishing between two common scenarios:\n",
    "\n",
    "### Scenario 1: Files in a Single Folder\n",
    "- Description: If you've obtained files from the Earthdata website and you have downloaded files individually or through running the bash script, they are typically consolidated within a single folder. \n",
    "    - EG: //you can take following steps to download files after selecting the range from EarthData Search:\n",
    "        - `chmod +x 4237267242-download`\n",
    "        - `./4237267242-download`\n",
    "- Recommendation: In this case, you can directly utilize \"Option 1\" for your operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff9d8c8",
   "metadata": {},
   "source": [
    "### Note:\n",
    "- You can see the locally downloaded files in the path: `multiple_netcdf_files`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1fa1e6c8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 236
    },
    "executionInfo": {
     "elapsed": 214,
     "status": "error",
     "timestamp": 1652679503238,
     "user": {
      "displayName": "Kikipessa Doll",
      "userId": "16203075636725704864"
     },
     "user_tz": 420
    },
    "id": "1fa1e6c8",
    "outputId": "7e95debd-55c7-47b2-e114-2120a08c6304"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../multiple_netcdf_files/\\\\oco2_LtCO2_210804_B11014Ar_220728230833s.nc4',\n",
       " '../../multiple_netcdf_files/\\\\oco2_LtCO2_210808_B11014Ar_220728231045s.nc4',\n",
       " '../../multiple_netcdf_files/\\\\oco2_LtCO2_210829_B11014Ar_220728232132s.nc4',\n",
       " '../../multiple_netcdf_files/\\\\oco2_LtCO2_210909_B11014Ar_220728225546s.nc4',\n",
       " '../../multiple_netcdf_files/\\\\oco2_LtCO2_210916_B11014Ar_220728225855s.nc4',\n",
       " '../../multiple_netcdf_files/\\\\oco2_LtCO2_210919_B11014Ar_220728230031s.nc4',\n",
       " '../../multiple_netcdf_files/\\\\oco2_LtCO2_210920_B11014Ar_220728230103s.nc4',\n",
       " '../../multiple_netcdf_files/\\\\oco2_LtCO2_210923_B11014Ar_220728230243s.nc4',\n",
       " '../../multiple_netcdf_files/\\\\oco2_LtCO2_210926_B11014Ar_220728230409s.nc4',\n",
       " '../../multiple_netcdf_files/\\\\oco2_LtCO2_211004_B11014Ar_220728223641s.nc4']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_a= ('../../multiple_netcdf_files/')\n",
    "\n",
    "# Collect the paths of each individual files\n",
    "file_names= []\n",
    "\n",
    "for file in os.listdir(path_a):\n",
    "    # Check whether file is in text format or not\n",
    "    if file.endswith(\".nc4\"):\n",
    "        file_path = f\"{path_a}\\{file}\"\n",
    "      \n",
    "        # Store the path location of each individual files\n",
    "        file_names.append(file_path)\n",
    "        \n",
    "        \n",
    "# check first 10 files path\n",
    "file_names[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004626ef",
   "metadata": {
    "id": "004626ef"
   },
   "source": [
    "## Scenario 2: Files in Different Subfolders\n",
    "- Description: Files downloaded from a cluster machine are often distributed across various subdirectories, which necessitates a different approach.\n",
    "- Recommendation: If your files are located in subdirectories, you'll need to employ an alternative method to manage and process them effectively.\n",
    "- How it works: \n",
    "    - 1. Provide the root direcory\n",
    "    - 2. Loop performs `joining` root + individual files at end paths of each directories\n",
    "    - 3. Concatenates the path from ROOT dir. to individual file path from each dir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ced6be4",
   "metadata": {
    "id": "5ced6be4"
   },
   "outputs": [],
   "source": [
    "# # list fo FILES 2021\n",
    "# file_path_2021= []\n",
    "\n",
    "# for root, dirs, files in os.walk('../../../Clusters_DATA_oil/OCO-2/2018/'):\n",
    "#     for filename in files:\n",
    "#         print(os.path.join(root, filename))\n",
    "        \n",
    "#         # Append the files into list\n",
    "#         file_path_2021.append(os.path.join(root, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d457322a",
   "metadata": {
    "id": "d457322a"
   },
   "outputs": [],
   "source": [
    "#files= os.listdir('../ENTIRE_datasets/OCO-2_datasets/2019_2020/')\n",
    "\n",
    "# files= os.listdir('')\n",
    "# # LISTING the path of FILES\n",
    "# files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a27bf7",
   "metadata": {
    "id": "e4a27bf7"
   },
   "source": [
    "# Example: \n",
    "### Open a single file in netCDF format from the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71c5c0f8",
   "metadata": {
    "id": "71c5c0f8"
   },
   "outputs": [],
   "source": [
    "df_xco2= nc.Dataset(file_names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf971e06",
   "metadata": {
    "id": "cf971e06",
    "outputId": "10af2033-b003-4841-d57c-cc5db550fcb7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sounding_id',\n",
       " 'levels',\n",
       " 'bands',\n",
       " 'vertices',\n",
       " 'footprints',\n",
       " 'date',\n",
       " 'latitude',\n",
       " 'longitude',\n",
       " 'time',\n",
       " 'solar_zenith_angle',\n",
       " 'sensor_zenith_angle',\n",
       " 'xco2_quality_flag',\n",
       " 'xco2_qf_bitflag',\n",
       " 'xco2_qf_simple_bitflag',\n",
       " 'source_files',\n",
       " 'file_index',\n",
       " 'vertex_latitude',\n",
       " 'vertex_longitude',\n",
       " 'xco2',\n",
       " 'xco2_uncertainty',\n",
       " 'xco2_apriori',\n",
       " 'pressure_levels',\n",
       " 'co2_profile_apriori',\n",
       " 'xco2_averaging_kernel',\n",
       " 'pressure_weight']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df_xco2.variables.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1aa9ba",
   "metadata": {
    "id": "8f1aa9ba"
   },
   "source": [
    "### Function for changing DateTime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4133c955",
   "metadata": {
    "id": "4133c955"
   },
   "outputs": [],
   "source": [
    "# DATE time function\n",
    "def conv_date(d):\n",
    "    return datetime.strptime(str(d), '%Y%m%d%H%M%S%f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2ad694",
   "metadata": {
    "id": "cd2ad694"
   },
   "source": [
    "### Check the total files in the DIRECTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de96547b",
   "metadata": {
    "id": "de96547b",
    "outputId": "2c929c0a-183e-447c-d3cb-2bdb0dba76ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TotalFiles:  14\n"
     ]
    }
   ],
   "source": [
    "countFiles=0\n",
    "\n",
    "for j in file_names:\n",
    "    if j.endswith(\".nc4\"):\n",
    "        countFiles+=1\n",
    "        #print(j)\n",
    "        \n",
    "print('\\nTotalFiles: ', countFiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02875102",
   "metadata": {},
   "source": [
    "### Creating a new dir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5dbdf3b9",
   "metadata": {
    "id": "5dbdf3b9"
   },
   "outputs": [],
   "source": [
    "current_directory= os.getcwd()\n",
    "frames_folder= os.path.join(current_directory, r'csv_files')\n",
    "\n",
    "if not os.path.exists(frames_folder):\n",
    "    os.makedirs(frames_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d135ca",
   "metadata": {
    "id": "d7d135ca"
   },
   "source": [
    "## Function:\n",
    "* Function below takes individual path of files and converts to CSV/TXT format\n",
    "* Converted files are created on the same dir. of the code\n",
    "- NOTE: Here, in this script ENTIRE dataframe are filtered by GOOD quality_flag->0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5bfa8617",
   "metadata": {
    "id": "5bfa8617"
   },
   "outputs": [],
   "source": [
    "def convHdf(path_file, n=0):\n",
    "\n",
    "    data= nc.Dataset(path_file)\n",
    "\n",
    "    # get the HDF data and convert to CSV\n",
    "    df_xco2= pd.DataFrame()\n",
    "\n",
    "    df_xco2['Xco2']= data.variables['xco2'][:]\n",
    "    df_xco2['Latitude']= data.variables['latitude'][:]\n",
    "    df_xco2['Longitude']= data.variables['longitude'][:] \n",
    "    df_xco2['quality_flag']= data.variables['xco2_quality_flag'][:] \n",
    "    \n",
    "    # Date\n",
    "    df_xco2['DateTime']= data.variables['sounding_id'][:]\n",
    "    \n",
    "    #Convert soundingID to datetime format\n",
    "    df_xco2['DateTime']= df_xco2['DateTime'].apply(conv_date)\n",
    "    df_xco2['DateTime']= pd.to_datetime(df_xco2['DateTime'])\n",
    "    \n",
    "    # YEAR and month column\n",
    "    df_xco2['Year']= df_xco2['DateTime'].dt.year\n",
    "    df_xco2['Month']= df_xco2['DateTime'].dt.month\n",
    "    df_xco2['Day']= df_xco2['DateTime'].dt.day\n",
    "    \n",
    "    # Refine the ENTIRE dataframe by GOOD quality_flag->0\n",
    "    # NOTE: REDUCES the size of the file\n",
    "    df_xco2= df_xco2[df_xco2['quality_flag'] == 0]   \n",
    "    \n",
    "   \n",
    "    date= str(data.variables['sounding_id'][0])      \n",
    "    \n",
    "    # create a CSV and store on new folder: csv_files\n",
    "    df_xco2.to_csv('csv_files'+'/'+ data.Sensor+'_xco2_'+ date+'_.txt', index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7140ef72",
   "metadata": {
    "id": "7140ef72"
   },
   "source": [
    "## Similar work with OCO3's SIF files netCDF to CSV conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbfabb7",
   "metadata": {
    "id": "fbbfabb7"
   },
   "outputs": [],
   "source": [
    "# # FUNCTION to convert data\n",
    "# def convOCO3(path_file, n=0):\n",
    "\n",
    "#     #path= '../hdf_format/Los_angeles_GROUPED/'\n",
    "#     data= nc.Dataset(path_file)\n",
    "\n",
    "#     # get the HDF data and convert to CSV\n",
    "#     df_sif= pd.DataFrame()\n",
    "\n",
    "#     df_sif['sif_757nm']= data.variables['Daily_SIF_757nm'][:]\n",
    "#     df_sif['Latitude']= data.variables['Latitude'][:]\n",
    "#     df_sif['Longitude']= data.variables['Longitude'][:] \n",
    "#     df_sif['quality_flag']= data.variables['Quality_Flag'][:] \n",
    "    \n",
    "#     # Date\n",
    "#     # Date time not found \n",
    "# #     df_xco2['DateTime']= data.variables['sounding_id'][:]\n",
    "    \n",
    "# #     #Convert soundingID to datetime format\n",
    "# #     df_xco2['DateTime']= df_xco2['DateTime'].apply(conv_date)\n",
    "# #     df_xco2['DateTime']= pd.to_datetime(df_xco2['DateTime'])\n",
    "    \n",
    "# #     # YEAR and month column\n",
    "# #     df_xco2['Year']= df_xco2['DateTime'].dt.year\n",
    "# #     df_xco2['Month']= df_xco2['DateTime'].dt.month\n",
    "# #     df_xco2['Day']= df_xco2['DateTime'].dt.day\n",
    "    \n",
    "    \n",
    "#     # xco2 quality flag -> 0\n",
    "#  #   df_sif= df_sif[df_sif['quality_flag'] == 0]\n",
    "    \n",
    "# #    date= str(data.variables['sounding_id'][0])                                   \n",
    "#     # create a CSV\n",
    "#     # OCO3 sensor\n",
    "#     df_sif.to_csv(data.sensor[:5]+'_sif_'+str(n)+ '_.txt', index= False)\n",
    "# #     df_xco2.to_feather(data.Sensor+'_xco2_'+ date+'_.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1506ef2f",
   "metadata": {
    "id": "1506ef2f"
   },
   "source": [
    "## Testing: Single file conversion and open with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6be0ec39",
   "metadata": {
    "id": "6be0ec39"
   },
   "outputs": [],
   "source": [
    "convHdf(file_names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40eeab1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Xco2</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>quality_flag</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>415.94247</td>\n",
       "      <td>-42.315613</td>\n",
       "      <td>-157.57877</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-08-04 00:24:05.760</td>\n",
       "      <td>2021</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>415.47308</td>\n",
       "      <td>-42.302628</td>\n",
       "      <td>-157.63130</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-08-04 00:24:05.780</td>\n",
       "      <td>2021</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>415.41177</td>\n",
       "      <td>-42.303930</td>\n",
       "      <td>-157.55707</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-08-04 00:24:06.050</td>\n",
       "      <td>2021</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>414.96786</td>\n",
       "      <td>-42.286022</td>\n",
       "      <td>-157.56154</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-08-04 00:24:06.350</td>\n",
       "      <td>2021</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>415.89227</td>\n",
       "      <td>-42.273420</td>\n",
       "      <td>-157.61390</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-08-04 00:24:06.370</td>\n",
       "      <td>2021</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Xco2   Latitude  Longitude  quality_flag                 DateTime  \\\n",
       "0  415.94247 -42.315613 -157.57877             0  2021-08-04 00:24:05.760   \n",
       "1  415.47308 -42.302628 -157.63130             0  2021-08-04 00:24:05.780   \n",
       "2  415.41177 -42.303930 -157.55707             0  2021-08-04 00:24:06.050   \n",
       "3  414.96786 -42.286022 -157.56154             0  2021-08-04 00:24:06.350   \n",
       "4  415.89227 -42.273420 -157.61390             0  2021-08-04 00:24:06.370   \n",
       "\n",
       "   Year  Month  Day  \n",
       "0  2021      8    4  \n",
       "1  2021      8    4  \n",
       "2  2021      8    4  \n",
       "3  2021      8    4  \n",
       "4  2021      8    4  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## read the file\n",
    "df= pd.read_csv(\"csv_files/OCO-2_xco2_2021080400235307_.txt\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c367997",
   "metadata": {
    "id": "4c367997"
   },
   "source": [
    "## RUN the following cell \n",
    "- below provided few lines of code will iterate over every netCDF files and convert to CSV files and save to dir. `csv_files`\n",
    "- NOTE: Filtering XCO2 quality flag(0) to reduce the total size of file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221c73b6",
   "metadata": {
    "id": "221c73b6"
   },
   "outputs": [],
   "source": [
    "# using Function to READ FILES from the direcotry and convert all netCDF files to csv/txt    \n",
    "for j in range(0, len(file_names)):\n",
    "  \n",
    "       # EG to read FIRST dataset from THE DIRECTORY       \n",
    "        convHdf(file_names[j], j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d89d124",
   "metadata": {
    "id": "8d89d124"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Conversion_NETCDF_to_CSV_2019_2020.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
